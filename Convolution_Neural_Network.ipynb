{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPfwEn7vp74S8oTS//frs11",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wlrma0108/Pytorch/blob/main/Convolution_Neural_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXPaXLLY2nlG",
        "outputId": "b3f4f31c-43ed-496f-88e7-9553533e805e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "metadata": {
        "id": "i2DRl9_m2nhi"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device=torch.device('cuda:0'if torch.cuda.is_available() else 'cpu')\n"
      ],
      "metadata": {
        "id": "fl0-WOf72ne8"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs=5\n",
        "num_classes =10\n",
        "batch_size =100\n",
        "learning_rate=0.001"
      ],
      "metadata": {
        "id": "oSJxMqzp2ncR"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset=torchvision.datasets.MNIST(root='../../data',train=True, transform=transforms.ToTensor(), download=True)\n",
        "test_dataset=torchvision.datasets.MNIST(root='../../data', train=False, transform=transforms.ToTensor())\n",
        "train_loader=torch.utils.data.DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=True)\n",
        "test_loader=torch.utils.data.DataLoader(dataset=test_dataset,batch_size=batch_size,shuffle=False)"
      ],
      "metadata": {
        "id": "oI8tPltU2nZu"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.modules.batchnorm import BatchNorm2d\n",
        "class ConvNet(nn.Module):\n",
        "  def __init__(self,num_classes=10):\n",
        "    super(ConvNet,self).__init__()\n",
        "    self.layer1= nn.Sequential(\n",
        "        nn.Conv2d(1,16,kernel_size=5,stride=1,padding=2),\n",
        "        nn.BatchNorm2d(16),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2,stride=2))\n",
        "    self.layer2=nn.Sequential(\n",
        "        nn.Conv2d(16,32,kernel_size=5,stride=1, padding=2),\n",
        "        nn.BatchNorm2d(32),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "    self.fc=nn.Linear(7*7*32,num_classes)    \n",
        "    \n",
        "\n",
        "\n",
        "  def forward(self,x):\n",
        "      out= self.layer1(x)\n",
        "      out= self.layer2(out)\n",
        "      out=out.reshape(out.size(0),-1)\n",
        "      out=self.fc(out)\n",
        "      return out\n",
        "\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "xe0fdd8d2nXD"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ConvNet(num_classes).to(device)\n",
        "criterion=nn.CrossEntropyLoss()\n",
        "optimizer=torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "rJN602279DsJ"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_step=len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "  for i,(images,labels) in enumerate(train_loader):\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "    \n",
        "    outputs = model(images)\n",
        "    loss=criterion(outputs,labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (i+1) %100 ==0:\n",
        "      print('Epoch [{}/{},step [{}/{}],Loss:{:.4f}'.format(epoch+1,num_epochs,i+1,total_step,loss.item()))\n",
        "\n",
        "\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    correct=0\n",
        "    total=0\n",
        "    for images,labels in test_loader:\n",
        "      images=images.to(device)\n",
        "      labels =labels.to(device)\n",
        "      outputs = model(images)\n",
        "      _,predicted = torch.max(outputs.data,1)\n",
        "      total+=labels.size(0)\n",
        "      correct+=(predicted==labels).sum().item()\n",
        "\n",
        "\n",
        "    print('Test Accuracy of the model in the 10000 test images: {} %'.format(100*correct/total))\n"
      ],
      "metadata": {
        "id": "p7eHhCGf2nUc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d94bad40-dc0b-42fe-8895-abf70e23668f"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5,step [100/600],Loss:0.1154\n",
            "Epoch [1/5,step [200/600],Loss:0.0769\n",
            "Epoch [1/5,step [300/600],Loss:0.1621\n",
            "Epoch [1/5,step [400/600],Loss:0.2081\n",
            "Epoch [1/5,step [500/600],Loss:0.0380\n",
            "Epoch [1/5,step [600/600],Loss:0.0700\n",
            "Test Accuracy of the model in the 10000 test images: 98.1 %\n",
            "Epoch [2/5,step [100/600],Loss:0.0939\n",
            "Epoch [2/5,step [200/600],Loss:0.0243\n",
            "Epoch [2/5,step [300/600],Loss:0.0089\n",
            "Epoch [2/5,step [400/600],Loss:0.0527\n",
            "Epoch [2/5,step [500/600],Loss:0.0400\n",
            "Epoch [2/5,step [600/600],Loss:0.0124\n",
            "Test Accuracy of the model in the 10000 test images: 98.77 %\n",
            "Epoch [3/5,step [100/600],Loss:0.0113\n",
            "Epoch [3/5,step [200/600],Loss:0.0144\n",
            "Epoch [3/5,step [300/600],Loss:0.0197\n",
            "Epoch [3/5,step [400/600],Loss:0.0056\n",
            "Epoch [3/5,step [500/600],Loss:0.0083\n",
            "Epoch [3/5,step [600/600],Loss:0.0042\n",
            "Test Accuracy of the model in the 10000 test images: 98.8 %\n",
            "Epoch [4/5,step [100/600],Loss:0.0439\n",
            "Epoch [4/5,step [200/600],Loss:0.0108\n",
            "Epoch [4/5,step [300/600],Loss:0.0392\n",
            "Epoch [4/5,step [400/600],Loss:0.0202\n",
            "Epoch [4/5,step [500/600],Loss:0.0341\n",
            "Epoch [4/5,step [600/600],Loss:0.0023\n",
            "Test Accuracy of the model in the 10000 test images: 99.01 %\n",
            "Epoch [5/5,step [100/600],Loss:0.0548\n",
            "Epoch [5/5,step [200/600],Loss:0.0016\n",
            "Epoch [5/5,step [300/600],Loss:0.0167\n",
            "Epoch [5/5,step [400/600],Loss:0.0617\n",
            "Epoch [5/5,step [500/600],Loss:0.0074\n",
            "Epoch [5/5,step [600/600],Loss:0.0317\n",
            "Test Accuracy of the model in the 10000 test images: 98.91 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'model.ckpt')"
      ],
      "metadata": {
        "id": "J-9Mkv0X2nRt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}